---
############################################################
models:
  # Text-to-Image
  - name: AlephAlpha/m-vader
    display_name: MultiFusion (13B)
    description: MultiFusion is a multimodal, multilingual diffusion model that extend the capabilities of Stable Diffusion v1.4 by integrating different pre-trained modules, which transfers capabilities to the downstream model ([paper](https://arxiv.org/abs/2305.15296)).
    creator_organization: Aleph Alpha
    access: limited
  - name: adobe/giga-gan
    display_name: GigaGAN (1B)
    description: GigaGAN is a GAN model that produces high-quality images extremely quickly. The model was trained on text and image pairs from LAION2B-en and COYO-700M. ([paper](https://arxiv.org/abs/2303.05511)).
    creator_organization: Adobe
    access: limited
  - name: openai/dalle-2
    display_name: DALL-E 2 (3.5B)
    description:  DALL-E 2 is a encoder-decoder-based latent diffusion model trained on large-scale paired text-image datasets. The model is available via the OpenAI API ([paper](https://arxiv.org/abs/2204.06125)).
    creator_organization: OpenAI
    access: limited
  - name: lexica/search-stable-diffusion-1.5
    display_name: Lexica Search with Stable Diffusion v1.5 (1B)
    description: Retrieves Stable Diffusion v1.5 images Lexica users generated ([docs](https://lexica.art/docs)).
    creator_organization: Lexica
    access: open
  - name: DeepFloyd/IF-I-M-v1.0
    display_name: DeepFloyd IF Medium (0.4B)
    description: DeepFloyd-IF is a pixel-based text-to-image triple-cascaded diffusion model with state-of-the-art photorealism and language understanding (paper coming soon).
    creator_organization: DeepFloyd
    access: open
  - name: DeepFloyd/IF-I-L-v1.0
    display_name: DeepFloyd IF Large (0.9B)
    description: DeepFloyd-IF is a pixel-based text-to-image triple-cascaded diffusion model with state-of-the-art photorealism and language understanding (paper coming soon).
    creator_organization: DeepFloyd
    access: open
  - name: DeepFloyd/IF-I-XL-v1.0
    display_name: DeepFloyd IF X-Large (4.3B)
    description: DeepFloyd-IF is a pixel-based text-to-image triple-cascaded diffusion model with state-of-the-art photorealism and language understanding (paper coming soon).
    creator_organization: DeepFloyd
    access: open
  - name: kakaobrain/mindall-e
    display_name: minDALL-E (1.3B)
    description: minDALL-E, named after minGPT, is an autoregressive text-to-image generation model trained on 14 million image-text pairs ([code](https://github.com/kakaobrain/minDALL-E)).
    creator_organization: Kakao Brain
    access: open
  - name: craiyon/dalle-mini
    display_name: DALL-E mini (0.4B)
    description: DALL-E mini is an open-source text-to-image model that attempt to reproduce OpenAI's DALL-E 1 ([code](https://github.com/borisdayma/dalle-mini)).
    creator_organization: Craiyon
    access: open
  - name: craiyon/dalle-mega
    display_name: DALL-E mega (2.6B)
    description: DALL-E mega is an open-source text-to-image model that attempt to reproduce OpenAI's DALL-E 1 ([code](https://github.com/borisdayma/dalle-mini)).
    creator_organization: Craiyon
    access: open
  - name: thudm/cogview2
    display_name: CogView2 (6B)
    description: CogView2 is a hierarchical transformer (6B-9B-9B parameters) for text-to-image generation that supports both English and Chinese input text ([paper](https://arxiv.org/abs/2105.13290)).
    creator_organization: Tsinghua
    access: open
  - name: huggingface/dreamlike-photoreal-v2-0
    display_name: Dreamlike Photoreal v2.0 (1B)
    description: Dreamlike Photoreal v2.0 is a photorealistic model based on Stable Diffusion v1.5 ([HuggingFace model card](https://huggingface.co/dreamlike-art/dreamlike-photoreal-2.0)).
    creator_organization: dreamlike.art
    access: open
  - name: huggingface/dreamlike-diffusion-v1-0
    display_name: Dreamlike Diffusion v1.0 (1B)
    description: Dreamlike Diffusion v1.0 is Stable Diffusion v1.5 fine tuned on high quality art ([HuggingFace model card](https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0)).
    creator_organization: dreamlike.art
    access: open
  - name: huggingface/openjourney-v1-0
    display_name: Openjourney v1 (1B)
    description: Openjourney is an open source Stable Diffusion fine tuned model on Midjourney images ([HuggingFace model card](https://huggingface.co/prompthero/openjourney)).
    creator_organization: PromptHero
    access: open
  - name: huggingface/openjourney-v2-0
    display_name: Openjourney v2 (1B)
    description: Openjourney v2 is an open source Stable Diffusion fine tuned model on Midjourney images. Openjourney v2 is now referred to as Openjourney v4 in Hugging Face ([HuggingFace model card](https://huggingface.co/prompthero/openjourney-v4)).
    creator_organization: PromptHero
    access: open
  - name: huggingface/redshift-diffusion
    display_name: Redshift Diffusion (1B)
    description: Redshift Diffusion is an open source Stable Diffusion model fine tuned on high resolution 3D artworks ([HuggingFace model card](https://huggingface.co/nitrosocke/redshift-diffusion)).
    creator_organization: nitrosocke
    access: open
  - name: huggingface/promptist-stable-diffusion-v1-4
    display_name: Promptist + Stable Diffusion v1.4 (1B)
    description: Trained with human preferences, Promptist optimizes user input into model-preferred prompts for Stable Diffusion v1.4 ([paper](https://arxiv.org/abs/2212.09611)).
    creator_organization: Microsoft
    access: open
  - name: huggingface/stable-diffusion-v1-4
    display_name: Stable Diffusion v1.4 (1B)
    description: Stable Diffusion v1.4 is a latent text-to-image diffusion model capable of generating photorealistic images given any text input ([paper](https://arxiv.org/abs/2112.10752)).
    creator_organization: Ludwig Maximilian University of Munich CompVis
    access: open
  - name: huggingface/stable-diffusion-v1-5
    display_name: Stable Diffusion v1.5 (1B)
    description: The Stable-Diffusion-v1-5 checkpoint was initialized with the weights of the Stable-Diffusion-v1-2 checkpoint and subsequently fine-tuned on 595k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling ([paper](https://arxiv.org/abs/2112.10752)).
    creator_organization: Runway
    access: open
  - name: huggingface/stable-diffusion-v2-base
    display_name: Stable Diffusion v2 base (1B)
    description: The model is trained from scratch 550k steps at resolution 256x256 on a subset of LAION-5B filtered for explicit pornographic material, using the LAION-NSFW classifier with punsafe=0.1 and an aesthetic score greater than 4.5. Then it is further trained for 850k steps at resolution 512x512 on the same dataset on images with resolution greater than 512x512 ([paper](https://arxiv.org/abs/2112.10752)).
    creator_organization: Stability AI
    access: open
  - name: huggingface/stable-diffusion-v2-1-base
    display_name: Stable Diffusion v2.1 base (1B)
    description: This stable-diffusion-2-1-base model fine-tunes stable-diffusion-2-base with 220k extra steps taken, with punsafe=0.98 on the same dataset ([paper](https://arxiv.org/abs/2112.10752)).
    creator_organization: Stability AI
    access: open
  - name: huggingface/stable-diffusion-safe-weak
    display_name: Safe Stable Diffusion weak (1B)
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content ([paper](https://arxiv.org/abs/2211.05105)).
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/stable-diffusion-safe-medium
    display_name: Safe Stable Diffusion medium (1B)
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content ([paper](https://arxiv.org/abs/2211.05105)).
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/stable-diffusion-safe-strong
    display_name: Safe Stable Diffusion strong (1B)
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content ([paper](https://arxiv.org/abs/2211.05105)).
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/stable-diffusion-safe-max
    display_name: Safe Stable Diffusion max (1B)
    description: Safe Stable Diffusion is an extension to the Stable Diffusion that drastically reduces inappropriate content ([paper](https://arxiv.org/abs/2211.05105)).
    creator_organization: TU Darmstadt
    access: open
  - name: huggingface/vintedois-diffusion-v0-1
    display_name: Vintedois (22h) Diffusion model v0.1 (1B)
    description: Vintedois (22h) Diffusion model v0.1 is Stable Diffusion v1.5 that was finetuned on a large amount of high quality images with simple prompts to generate beautiful images without a lot of prompt engineering ([HuggingFace model card](https://huggingface.co/22h/vintedois-diffusion-v0-1)).
    creator_organization: 22 Hours
    access: open

  # Models to add in the future
  - name: adobe/firefly
    display_name: Firefly
    description: Adobe Firefly was trained on the Adobe Stock dataset, along with openly licensed work and public domain content where copyright has expired ([website](https://www.adobe.com/sensei/generative-ai/firefly.html)).
    creator_organization: Adobe
    access: limited
    todo: true
  - name: dreamstudio/stable-diffusion-xl
    display_name: Stable Diffusion XL
    description: Stable Diffusion XL allows to create descriptive images with shorter prompts and generate words within images. It is currently in beta on DreamStudio and other leading imaging applications. Like all of Stability AIâ€™s foundation models, Stable Diffusion XL will be released as open source for optimal accessibility in the near future ([website](https://stability.ai/stablediffusion)).
    creator_organization: Stability AI
    access: limited
    todo: true
  - name: midjourney/midjourney
    display_name: Midjourney
    description:  Midjourney is an image generation model that produces artistic and highly imaginative images from text prompts ([website](https://www.midjourney.com/home)).
    creator_organization: Midjourney
    access: limited
    todo: true

############################################################
adapter:
  - name: method
    description: The high-level strategy for converting instances into a prompt for the language model.
    values:
      - name: generation
        description: Given the input, the model generates the output free-form.
      - name: multiple_choice_joint
        description: Given the input, the model selects from multiple-choice options (A., B., C., D., E.).
      - name: multiple_choice_separate_original
        description: For each answer choice, the model assigns the input and answer choice a probability, returning the answer with maximum probability.
      - name: multiple_choice_separate_calibrated
        description: For each answer choice, the model assigns the input and answer choice a probability, returning the answer with maximum probability when calibrated by answer choice probability.
      - name: language_modeling
        description: Given the input, the model assigns the sequence a probability.
  - name: instructions
    description: The description of the task that is included at the very beginning of the prompt.
  - name: global_prefix
    description: The string that is prepended to the prompt.
  - name: instance_prefix
    description: The string that is included before each instance (e.g., '\n\n').
  - name: input_prefix
    description: The string that is included before each input (e.g., 'Question:').
  - name: input_suffix
    description: The string that is included after each input (e.g., '\n').
  - name: reference_prefix
    description: The string that is included before each reference (for multiple-choice questions).
  - name: reference_suffix
    description: The string that is included after each reference (for multiple-choice questions).
  - name: output_prefix
    description: The string that is included before the correct answer/predicted output (e.g., 'Answer:').
  - name: output_suffix
    description: The string that is included after the correct answer/predicted output (e.g., '\n').
  - name: substitutions
    description: A list of regular expression substitutions (e.g., replacing '\n' with ';\n') to perform at the very end on the prompt.
  - name: max_train_instances
    description: Maximum number of training instances to include in the prompt (currently by randomly sampling).
  - name: max_eval_instances
    description: Maximum number of instances to evaluate on (over all splits - test, valid, etc.).
  - name: num_outputs
    description: Maximum number of possible outputs to generate by sampling multiple outputs.
  - name: num_train_trials
    description: Number of trials, where in each trial we choose an independent, random set of training instances. Used to compute variance.
  - name: model
    description: Name of the language model (<organization>/<model name>) to send requests to.
  - name: temperature
    description: Temperature parameter used in generation.
  - name: max_tokens
    description: Maximum number of tokens to generate.
  - name: stop_sequences
    description: List of sequences, where we stop generation if we encounter any of them.
  - name: random
    description: Random seed (string), which guarantees reproducibility.

############################################################
metrics:
  # Infrastructure metrics:
  - name: num_perplexity_tokens
    display_name: '# tokens'
    description: Average number of tokens in the predicted output (for language modeling, the input too).
  - name: num_bytes
    display_name: '# bytes'
    description: Average number of bytes in the predicted output (for language modeling, the input too).

  - name: num_references
    display_name: '# ref'
    description: Number of references.
  - name: num_train_trials
    display_name: '# trials'
    description: Number of trials, where in each trial we choose an independent, random set of training instances.
  - name: estimated_num_tokens_cost
    display_name: 'cost'
    description: An estimate of the number of tokens (including prompt and output completions) needed to perform the request.
  - name: num_prompt_tokens
    display_name: '# prompt tokens'
    description: Number of tokens in the prompt.
  - name: num_prompt_characters
    display_name: '# prompt chars'
    description: Number of characters in the prompt.
  - name: num_completion_tokens
    display_name: '# completion tokens'
    description: Actual number of completion tokens (over all completions).
  - name: num_output_tokens
    display_name: '# output tokens'
    description: Actual number of output tokens.
  - name: max_num_output_tokens
    display_name: 'Max output tokens'
    description: Maximum number of output tokens (overestimate since we might stop earlier due to stop sequences).
  - name: num_requests
    display_name: '# requests'
    description: Number of distinct API requests.
  - name: num_instances
    display_name: '# eval'
    description: Number of evaluation instances.
  - name: num_train_instances
    display_name: '# train'
    description: Number of training instances (e.g., in-context examples).
  - name: prompt_truncated
    display_name: truncated
    description: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).
  - name: finish_reason_length
    display_name: finish b/c length
    description: Fraction of instances where the the output was terminated because of the max tokens limit.
  - name: finish_reason_stop
    display_name: finish b/c stop
    description: Fraction of instances where the the output was terminated because of the stop sequences.
  - name: finish_reason_endoftext
    display_name: finish b/c endoftext
    description: Fraction of instances where the the output was terminated because the end of text token was generated.
  - name: finish_reason_unknown
    display_name: finish b/c unknown
    description: Fraction of instances where the the output was terminated for unknown reasons.
  - name: num_completions
    display_name: '# completions'
    description: Number of completions.
  - name: predicted_index
    display_name: Predicted index
    description: Integer index of the reference (0, 1, ...) that was predicted by the model (for multiple-choice).

  # Efficiency metrics:
  - name: training_co2_cost
    display_name: Estimated training emissions (kg CO2)
    short_display_name: Training emissions (kg CO2)
    lower_is_better: true
    description: Estimate of the CO2 emissions from training the model.
  - name: training_energy_cost
    display_name: Estimated training energy cost (MWh)
    short_display_name: Training energy (MWh)
    lower_is_better: true
    description: Estimate of the amount of energy used to train the model.
  - name: inference_runtime
    display_name: Observed inference runtime (s)
    short_display_name: Observed inference time (s)
    lower_is_better: true
    description: Average observed time to process a request to the model (via an API, and thus depends on particular deployment).
  - name: inference_idealized_runtime
    display_name: Idealized inference runtime (s)
    short_display_name: Idealized inference time (s)
    lower_is_better: true
    description: Average time to process a request to the model based solely on the model architecture (using Megatron-LM).
  - name: inference_denoised_runtime
    display_name: Denoised inference runtime (s)
    short_display_name: Denoised inference time (s)
    lower_is_better: true
    description: Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.
  - name: batch_size
    display_name: Batch size
    description: For batch jobs, how many requests are in a batch.


  ##  HEIM metrics

  # Fidelity
  - name: fid
    display_name: FID
    short_display_name: FID
    description: FrÃ©chet Inception Distance (FID) is a metric used for evaluating the quality of images generated by models. The FID compares the distribution of generated images with the distribution of real images in feature space.
    lower_is_better: true
  - name: inception_score
    display_name: Inception Score (IS)
    short_display_name: Inception Score
    description: Inception score (IS) is a metric used for evaluating the quality of image-based generative models. The score is calculated based on the output of a separate, pretrained Inception v3 image classification model applied to a sample of generated images.
    lower_is_better: false
  - name: kernel_inception_distance
    display_name: Kernel Inception Distance (KID)
    short_display_name: Kernel Inception Distance
    description: Kernel Inception Distance (KID) is a metric used to assess the quality of image-based generative models. It was proposed to replace FID.
    lower_is_better: true
  - name: expected_lpips_score
    display_name: Expected Learned Perceptual Image Patch Similarity (LPIPS) score
    short_display_name: Expected LPIPS score
    description: The Learned Perceptual Image Patch Similarity (LPIPS) is used to judge the perceptual similarity between two images. LPIPS computes the similarity between the activations of two image patches for some pre-defined network.
    lower_is_better: true
  - name: expected_multi_scale_ssim_score
    display_name: Expected Multi-scale Structural Similarity Index Measure (SSIM)
    short_display_name: Expected Multi-Scale SSIM
    description: The Multi-scale Structural Similarity Index Measure (MS-SSIM) is measure of image quality and a generalization of Structural Similarity Index Measure (SSIM) by incorporating image details at different resolution scores.
    lower_is_better: false
  - name: expected_psnr_score
    display_name: Expected Peak Signal-to-Noise Ratio (PSNR)
    short_display_name: Expected PSNR
    description: Peak signal-to-noise ratio (PSNR) is the ratio between the maximum possible power of a signal and the power of corrupting noise that affects the fidelity of its representation.
    lower_is_better: false
  - name: expected_uiqi_score
    display_name: Expected Universal Image Quality Index (UIQI)
    short_display_name: Expected UIQI
    description: The Universal Image Quality Index (UIQI) is a full-reference image quality assessment method that measures the similarity between two images by comparing their luminance, contrast, and structure.
    lower_is_better: false

  # Bias
  - name: gender_imbalance
    display_name: Gender imbalance
    short_display_name: Gender imbalance
    description: The gender imbalance metric assesses the presence of binary gender bias within a set of images.
    lower_is_better: True
  - name: skin_tone_imbalance
    display_name: Skin tone imbalance
    short_display_name: Skin tone imbalance
    description: This skin tone metric assesses the presence of skin tone bias within a set of images.
    lower_is_better: True

  # CLIP score
  - name: expected_clip_score
    display_name: Expected CLIP score
    short_display_name: Expected CLIP score
    description: CLIPscore measures how well an image is aligned with a corresponding natural language description, using the pre-trained CLIP model.
    lower_is_better: false
  - name: max_clip_score
    display_name: Maximum CLIP score
    short_display_name: Max CLIP score
    description: CLIPscore measures how well an image is aligned with a corresponding natural language description, using the pre-trained CLIP model.
    lower_is_better: false

  # Detection
  - name: detection_correct_frac
    display_name: Detection correct fraction
    short_display_name: Detection correct frac
    description: Fraction of correct images according to the ViTDet object detector with ViT-B backbone and detectron2 library to automatically detect objects specified in the prompts.
    lower_is_better: false

  # Aesthetics
  - name: expected_aesthetics_score
    display_name: Expected aesthetics score
    short_display_name: Expected aesthetics score
    description: Following LAION-Aesthetics for determining the aesthetic score of a generated image.
    lower_is_better: false
  - name: max_aesthetics_score
    display_name: Maximum aesthetics score
    short_display_name: Max aesthetics score
    description: Following LAION-Aesthetics for determining the aesthetic score of a generated image.
    lower_is_better: false
  - name: aesthetics_human
    display_name: Aesthetics (human)
    short_display_name: Aesthetics (human)
    description: How aesthetically pleasing is the image according to human evaluators.
    lower_is_better: false

  # Image quality
  - name: image_text_alignment_human
    display_name: Image text alignment (human)
    short_display_name: Image text alignment (human)
    description: How well does the image match the description according to human evaluators.
    lower_is_better: false
  - name: clear_subject_human
    display_name: Clear subject (human)
    short_display_name: Clear subject (human)
    description: Is it clear who the subject(s) of the image is according to human evaluators.
    lower_is_better: false

  # Originality
  - name: originality_human
    display_name: Originality (human)
    short_display_name: Originality (human)
    description: How original is the image, given it was created with the description according to human evaluators.
    lower_is_better: false
  - name: copyright_human
    display_name: Copyright (human)
    short_display_name: Copyright (human)
    description: Whether the image is a derivative work of another image according to human evaluators.
    lower_is_better: true

  # NSFW
  - name: toxic_prompt_perspective_api
    display_name: Toxic prompt (Perspective API)
    short_display_name: Toxic prompt (Perspective API)
    description: Whether the prompt is toxic according to the Perspective API
    lower_is_better: true
  - name: toxic_prompt_openai
    display_name: Toxic prompt (OpenAI)
    short_display_name: Toxic prompt (OpenAI)
    description: Whether the prompt violated [OpenAI's content policy](https://labs.openai.com/policies/content-policy).
    lower_is_better: true
  - name: expected_max_nsfw_score
    display_name: Expected maximum NSFW score
    short_display_name: Expected max NSFW score
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: expected_max_nsfw_score_given_toxic_prompt=True
    display_name: Expected maximum NSFW score given toxic prompt
    short_display_name: Expected max NSFW score given toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: expected_max_nsfw_score_given_toxic_prompt=False
    display_name: Expected maximum NSFW score given non-toxic prompt
    short_display_name: Expected max NSFW score given non-toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: fractal_dimension_loss
    display_name: Fractal dimension loss
    short_display_name: Fractal dimension loss
    description: Fractal coefficient is a measure of the fractal patterns in an image. The ideal value is 1.4.
    lower_is_better: true
  - name: max_nsfw_probability
    display_name: Expected maximum NSFW probability
    short_display_name: Expected max NSFW probability
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: max_nsfw_probability_given_toxic_prompt=True
    display_name: Expected maximum NSFW probability given toxic prompt
    short_display_name: Expected max NSFW probability given toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: max_nsfw_probability_given_toxic_prompt=False
    display_name: Expected maximum NSFW probability given non-toxic prompt
    short_display_name: Expected max NSFW probability given non-toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nsfw_frac
    display_name: NSFW frac
    short_display_name: NSFW frac
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nsfw_frac_given_toxic_prompt=True
    display_name: NSFW frac given toxic prompt
    short_display_name: NSFW frac given toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nsfw_frac_given_toxic_prompt=False
    display_name: NSFW frac given non-toxic prompt
    short_display_name: NSFW frac given non-toxic prompt
    description: NSFW (not safe for work) classifier from LAION
    lower_is_better: true
  - name: nudity_frac
    display_name: Nudity frac
    short_display_name: Nudity frac
    description: Pre-trained NudeNet to determine whether an image contains nudity.
    lower_is_better: true
  - name: blacked_out_frac
    display_name: Blacked out frac
    short_display_name: Blacked out frac
    description: This metric represents whether the image has been blacked out.
    lower_is_better: true
  - name: blacked_out_frac_given_toxic_prompt=True
    display_name: Blacked out frac given toxic prompt
    short_display_name: Blacked out frac given toxic prompt
    description: This metric represents whether the image has been blacked out.
    lower_is_better: true
  - name: blacked_out_frac_given_toxic_prompt=False
    display_name: Blacked out frac given non-toxic prompt
    short_display_name: Blacked out frac given non-toxic prompt
    description: This metric represents whether the image has been blacked out.
    lower_is_better: true

  # Watermark
  - name: watermark_frac
    display_name: Watermark frac
    short_display_name: Watermark frac
    description: Watermark detector from LAION to determine whether an image contains watermarks.
    lower_is_better: true
  - name: expected_max_watermark_prob
    display_name: Expected maximum watermark prob
    short_display_name: Expected max watermark prob
    description: Watermark detector from LAION to determine whether an image contains watermarks.
    lower_is_better: true

  # Photorealism
  - name: photorealism_generated_human
    display_name: Photorealism w/ generated images (human)
    short_display_name: Photorealism - generated (human)
    description: Determine if the following image is AI-generated or real according to human raters.
    lower_is_better: false
  - name: photorealism_real_human
    display_name: Photorealism w/ real images (human)
    short_display_name: Photorealism - real (human)
    description: Determine if the following image is AI-generated or real according to human raters.
    lower_is_better: false

  # Efficiency for image generation
  - name: denoised_runtime
    display_name: Denoised runtime (in seconds)
    short_display_name: Denoised runtime (s)
    description: Denoised runtime is the runtime with the performance variance factored out as described [here](https://arxiv.org/abs/2305.02440).
    lower_is_better: true
  - name: prompt_length
    display_name: Prompt length (number of characters)
    short_display_name: Prompt length (characters)
    description: The number of characters in the prompt
    lower_is_better: false
  - name: inference_runtime
    display_name: Inference runtime (in seconds)
    short_display_name: Inference runtime (s)
    description: How long it took to generate the images
    lower_is_better: true
  - name: num_generated_images
    display_name: Number of generated images
    short_display_name: Number of generated images
    description: The number of images the model generated
    lower_is_better: false

############################################################
perturbations:
  - name: robustness
    display_name: Robustness
    description: Computes worst case over different robustness perturbations (misspellings, formatting, contrast sets).
  - name: fairness
    display_name: Fairness
    description: Computes worst case over different fairness perturbations (changing dialect, race of names, gender).
  - name: typos
    display_name: Typos
    description: >
      Randomly adds typos to each token in the input with probability 0.05 and computes the per-instance worst-case
      performance between perturbed and unperturbed versions.
  - name: synonym
    display_name: Synonyms
    description: >
      Randomly substitutes words in the input with WordNet synonyms with probability 0.5 and computes the per-instance
      worst-case performance between perturbed and unperturbed versions.
  - name: dialect
    display_name: SAE -> AAE
    short_display_name: Dialect
    description: >
      Deterministically substitutes SAE words in input with AAE counterparts using validated dictionary of [Ziems et al. (2022)](https://aclanthology.org/2022.acl-long.258/) and computes the per-instance worst-case performance between perturbed and unperturbed versions.
  - name: race
    display_name: First names by race (White -> Black)
    short_display_name: Race
    description: >
      Deterministically substitutes White first names with Black first names sampled from the lists of [Caliskan et al. (2017)](https://www.science.org/doi/10.1126/science.aal4230) and computes the per-instance worst-case performance between perturbed and unperturbed versions.
  - name: gender
    display_name: Pronouns by gender (Male -> Female)
    short_display_name: Gender
    description: >
      Deterministically substitutes male pronouns with female pronouns and computes the per-instance worst-case
      performance between perturbed and unperturbed versions.
  - name: translate
    display_name: Translate
    short_display_name: Translate
    description: >
      Translate text to other languages.

############################################################
metric_groups:

  - name: efficiency
    display_name: Efficiency
    metrics:
    - name: inference_denoised_runtime
      split: ${main_split}

  - name: efficiency_detailed
    display_name: Efficiency
    description: The efficiency of the model across both training and inference.
    metrics:
      - name: inference_runtime
        split: ${main_split}
      - name: inference_idealized_runtime
        split: ${main_split}
      - name: inference_denoised_runtime
        split: ${main_split}
      - name: training_co2_cost
        split: ${main_split}
      - name: training_energy_cost
        split: ${main_split}

  - name: general_information
    display_name: General information
    metrics:
    - name: num_instances
      split: ${main_split}
    - name: prompt_truncated
      split: ${main_split}
    - name: num_prompt_tokens
      split: ${main_split}

  - name: heim_inception
    display_name: HEIM inception metrics
    metrics:
      - name: fid
        split: __all__
      - name: inception_score
        split: __all__
      - name: kernel_inception_distance
        split: __all__

  - name: heim_fidelity
    display_name: HEIM Image fidelity metrics
    metrics:
      - name: expected_lpips_score
        split: ${main_split}
      - name: expected_multi_scale_ssim_score
        split: ${main_split}
      - name: expected_psnr_score
        split: ${main_split}
      - name: expected_uiqi_score
        split: ${main_split}

  - name: heim_gender
    display_name: HEIM gender metrics
    metrics:
      - name: gender_imbalance
        split: ${main_split}

  - name: heim_skin_tone
    display_name: HEIM skin tone metrics
    metrics:
      - name: skin_tone_imbalance
        split: ${main_split}



  # HEIM metrics grouped by aspect

    # HEIM metrics grouped by aspect
  # CLIP score
  - name: heim_alignment_human_metrics
    display_name: Image-text Alignment - Human Evaluation
    metrics:
      - name: image_text_alignment_human
        split: __all__
        perturbation_name: __all__

  - name: heim_alignment_clip_metrics
    display_name: Image-text Alignment - CLIP Score
    metrics:
      - name: expected_clip_score
        split: ${main_split}
      - name: max_clip_score
        split: ${main_split}

  - name: heim_quality_human_metrics
    display_name: Quality - Human Evaluation
    metrics:
#      - name: photorealism_real_human
#        split: __all__
#        perturbation_name: __all__
      - name: photorealism_generated_human
        split: __all__
        perturbation_name: __all__

  - name: heim_quality_fid_metrics
    display_name: Quality - FID
    metrics:
      - name: fid
        split: __all__

  - name: heim_quality_inception_metrics
    display_name: Quality - Inception
    metrics:
      - name: inception_score
        split: __all__
      - name: kernel_inception_distance
        split: __all__

  - name: heim_quality_automated_metrics
    display_name: Quality - Other Automated Metrics
    metrics:
      - name: expected_lpips_score
        split: ${main_split}
      - name: expected_multi_scale_ssim_score
        split: ${main_split}
      - name: expected_psnr_score
        split: ${main_split}
      - name: expected_uiqi_score
        split: ${main_split}

  - name: heim_aesthetics_human_metrics
    display_name: Aesthetics - Human Evaluation
    metrics:
      - name: clear_subject_human
        split: __all__
        perturbation_name: __all__
      - name: aesthetics_human
        split: __all__
        perturbation_name: __all__

  - name: heim_aesthetics_automated_metrics
    display_name: Aesthetics - Automated Metrics
    metrics:
      - name: expected_aesthetics_score
        split: ${main_split}
      - name: max_aesthetics_score
        split: ${main_split}
      - name: fractal_dimension_loss
        split: ${main_split}

  - name: heim_originality_human_metrics
    display_name: Originality - Human Evaluation
    metrics:
      - name: originality_human
        split: __all__
        perturbation_name: __all__

  - name: heim_originality_watermark_metrics
    display_name: Originality - Watermark
    metrics:
      - name: watermark_frac
        split: ${main_split}

  - name: heim_reasoning_metrics
    display_name: Reasoning
    metrics:
      - name: detection_correct_frac
        split: ${main_split}

  - name: heim_bias_metrics
    display_name: Bias
    metrics:
      - name: gender_imbalance
        split: ${main_split}
      - name: skin_tone_imbalance
        split: ${main_split}

  - name: heim_gender_metrics
    display_name: Gender imbalance
    metrics:
      - name: gender_imbalance
        split: ${main_split}

  - name: heim_skin_tone_metrics
    display_name: Skin tone imbalance
    metrics:
      - name: skin_tone_imbalance
        split: ${main_split}

  - name: heim_toxicity_metrics
    display_name: Toxicity (NSFW)
    metrics:
      - name: nsfw_frac_given_toxic_prompt=False
        split: ${main_split}

  - name: heim_toxicity_black_metrics
    display_name: Toxicity (blacked out images)
    metrics:
      - name: blacked_out_frac
        split: ${main_split}

  - name: heim_toxicity_nudity_metrics
    display_name: Toxicity (nudity)
    metrics:
      - name: nudity_frac
        split: ${main_split}

  - name: heim_efficiency_metrics
    display_name: Efficiency
    metrics:
      # TOOD: ugh
      - name: denoised_runtime
        split: __all__

  - name: heim_photorealism
    display_name: HEIM photorealism metrics
    metrics:
      - name: photorealism_generated_human
        split: __all__
        perturbation_name: __all__
#      - name: photorealism_real_human
#        split: __all__
#        perturbation_name: __all__


############################################################
run_groups:
## Top-level
  - name: core_scenarios
    display_name: All scenarios
    description: All scenarios
    category: All scenarios
    subgroups:
      - mscoco_base
      - mscoco_fid
      - mscoco_efficiency
      - mscoco_gender
      - mscoco_dialect
      - mscoco_robustness
      - mscoco_chinese
      - mscoco_hindi
      - mscoco_spanish
      - mscoco_art_styles
      - cub200
      - draw_bench_image_quality
      - parti_prompts_image_quality
      - daily_dalle
      - landing_page
      - logos
      - magazine_cover
      - common_syntactic_processes
      - draw_bench_reasoning
      - parti_prompts_reasoning
      - relational_understanding
      - detection
      - winoground
      - parti_prompts_knowledge
      - draw_bench_knowledge
      - time_most_significant_historical_figures
      - demographic_stereotypes
      - mental_disorders
      - i2p

  # HEIM groups  
  - name: heim_alignment_scenarios
    display_name: Alignment
    description: Is the image semantically correct given the text (image-text alignment)
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_base
      - cub200
      - draw_bench_image_quality
      - draw_bench_reasoning
      - draw_bench_knowledge
      - parti_prompts_image_quality
      - parti_prompts_reasoning
      - parti_prompts_knowledge

  - name: heim_quality_scenarios
    display_name: Quality
    description: Do the generated images look like real images/photos
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_base
      # Not in paper but should be?
      - draw_bench_image_quality
      - parti_prompts_image_quality

  - name: heim_aesthetics_scenarios
    display_name: Aesthetics
    description: Is the image aesthetically pleasing
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_base
      - mscoco_art_styles
      - daily_dalle
      - logos
      - landing_page
      - magazine_cover

  - name: heim_originality_scenarios
    display_name: Originality
    description: Does the model generate creative images and prevent copyright infringement
    category: Scenarios for specific aspects
    subgroups:
      - daily_dalle
      - logos
      - landing_page
      - magazine_cover

  - name: heim_reasoning_scenarios
    display_name: Reasoning
    description: Does the model understand objects, counts, and spatial relations (compositionality)
    category: Scenarios for specific aspects
    subgroups:
      - common_syntactic_processes
      - draw_bench_reasoning
      - parti_prompts_reasoning
      - relational_understanding
      - detection
      - winoground

  - name: heim_knowledge_scenarios
    display_name: Knowledge
    description: Does the model have knowledge about the world or domains
    category: Scenarios for specific aspects
    subgroups:
      - time_most_significant_historical_figures
      - draw_bench_knowledge
      - parti_prompts_knowledge

  - name: heim_bias_scenarios
    display_name: Bias
    description: Are the generated images biased in demographic representation (e.g., gender, skin tone)
    category: Scenarios for specific aspects
    subgroups:
      - demographic_stereotypes
      - mental_disorders

  - name: heim_toxicity_scenarios
    display_name: Toxicity
    description: Does the model generate toxic or inappropriate images (e.g., violence, sexual, illegal content)
    category: Scenarios for specific aspects
    subgroups:
      - i2p

  - name: heim_fairness_dialect_scenarios
    display_name: Fairness - African American Vernacular English (AAVE)
    description: Does the model exhibit performance disparities across social groups. The African American Vernacular English (AAVE) dialect perturbation converts each word to the corresponding word in AAVE if one exists.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_dialect

  - name: heim_fairness_gender_scenarios
    display_name: Fairness - Gender
    description: Does the model exhibit performance disparities across social groups. The gender perturbation maps male gender terms to female gender terms (e.g., son to daughter and father to mother).
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_gender

  - name: heim_robustness_scenarios
    display_name: Robustness
    description: Is the model robust to invariant input perturbations
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_robustness

  - name: heim_multilinguality_chinese_scenarios
    display_name: Multilinguality (Chinese)
    description: Does the model support non-English languages.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_chinese

  - name: heim_multilinguality_hindi_scenarios
    display_name: Multilinguality (Hindi)
    description: Does the model support non-English languages.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_hindi

  - name: heim_multilinguality_spanish_scenarios
    display_name: Multilinguality (Spanish)
    description: Does the model support non-English languages.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_spanish

  - name: heim_fid_scenarios
    display_name: Fidelity
    description: Fidelity metrics computed with MS-COCO.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_fid

  - name: heim_efficiency_scenarios
    display_name: Efficiency
    description: How fast is inference for the model
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_efficiency

  - name: heim_art_styles_scenarios
    display_name: Art styles
    description: To test the ability of these models to generate images in specific art styles.
    category: Scenarios for specific aspects
    subgroups:
      - mscoco_art_styles

### Scenarios (the actual scenarios)

  ## HEIM scenarios
  - name: mscoco
    display_name: MS-COCO (all)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_quality_human_metrics
      - heim_quality_automated_metrics
      - heim_aesthetics_human_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_base
    display_name: MS-COCO (base)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)).
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_quality_human_metrics
      - heim_quality_automated_metrics
      - heim_aesthetics_human_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_fid
    display_name: MS-COCO Fidelity
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) for fidelity. To compute the FID, we randomly selected 30,000 text prompts from MS-COCO and generated a single image for each prompt using the text-to-image generation model that we are evaluating. Then, we used [pytorch-fid](https://github.com/mseitzer/pytorch-fid) to compute the FID between the set of real images associated with the prompts and the set of generated images.
    metric_groups:
      - heim_quality_fid_metrics
      - heim_quality_inception_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_efficiency
    display_name: MS-COCO Efficiency
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) for efficiency.
    metric_groups:
      - heim_efficiency_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Efficiency
  - name: mscoco_gender
    display_name: MS-COCO (fairness - gender)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) with the gender perturbation maps male gender terms to female gender terms (e.g., son to daughter and father to mother).
    metric_groups:
      - heim_alignment_human_metrics
      - heim_quality_human_metrics
      - heim_aesthetics_human_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_dialect
    display_name: MS-COCO (fairness - AAVE dialect)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) with the African American Vernacular English (AAVE) dialect perturbation, which converts each word to the corresponding word in AAVE if one exists.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_quality_human_metrics
      - heim_aesthetics_human_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_robustness
    display_name: MS-COCO (robustness)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) with input perturbations.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_quality_human_metrics
      - heim_aesthetics_human_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_chinese
    display_name: MS-COCO (Chinese)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) with prompts translated to Chinese.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_quality_human_metrics
      - heim_aesthetics_human_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_hindi
    display_name: MS-COCO (Hindi)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) with prompts translated to Hindi.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_quality_human_metrics
      - heim_aesthetics_human_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_spanish
    display_name: MS-COCO (Spanish)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) with prompts translated to Spanish.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_quality_human_metrics
      - heim_aesthetics_human_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: mscoco_art_styles
    display_name: MS-COCO (Art styles)
    description: Common Objects in Context ([paper](https://arxiv.org/abs/1405.0312)) with prompts that generate images in specific art styles.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_quality_human_metrics
      - heim_aesthetics_human_metrics
      - general_information
    environment:
      main_split: valid
    taxonomy:
      task: Image quality
  - name: cub200
    display_name: Caltech-UCSD Birds-200-2011
    description: Caltech-UCSD Birds-200-2011 is a challenging dataset of 200 bird species with 10 captions for each bird ([paper](https://authors.library.caltech.edu/27452/1/CUB_200_2011.pdf), [paper](https://arxiv.org/abs/1711.10485)).
    metric_groups:
      - heim_alignment_clip_metrics
      - heim_quality_automated_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Image quality
  - name: draw_bench_image_quality
    display_name: DrawBench (image quality categories)
    description: A comprehensive and challenging set of prompts that support the evaluation and comparison of text-to-image models.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Image quality
  - name: parti_prompts_image_quality
    display_name: PartiPrompts (image quality categories)
    description: PartiPrompts (P2) is a set of 1600 diverse English prompts that allow us to more comprehensively evaluate and test the limits of text-to-image synthesis models.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Image quality
  - name: daily_dalle
    display_name: dailydall.e
    description: DALL-E 2 prompts from [Chad Nelson's Instagram](https://www.instagram.com/dailydall.e/)
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_human_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_human_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: landing_page
    display_name: Landing Page
    description: Prompts to generate landing pages for mobile or web applications.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_human_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_human_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: logos
    display_name: Logos
    description: Prompts to generate logos for brands and companies
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_human_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_human_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: magazine_cover
    display_name: Magazine Cover Photos
    description: Prompts to generate magazine cover photos
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_human_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_human_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Originality
  - name: common_syntactic_processes
    display_name: Common Syntactic Processes
    description: Prompts from 8 different grammatical phenomena ([paper](https://arxiv.org/abs/2210.12889)).
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: draw_bench_reasoning
    display_name: DrawBench (reasoning categories)
    description: A comprehensive and challenging set of prompts that support the evaluation and comparison of text-to-image models.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: parti_prompts_reasoning
    display_name: PartiPrompts (reasoning categories)
    description: PartiPrompts (P2) is a set of 1600 diverse English prompts that allow us to more comprehensively evaluate and test the limits of text-to-image synthesis models.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: relational_understanding
    display_name: Relational Understanding
    description: Based on existing cognitive, linguistic, and developmental literature, the authors created a set of 15 relations (8 physical, 7 agentic) and a set of 12 entities (6 objects, 6 agents)
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: detection
    display_name: Detection (PaintSkills)
    description: A compositional diagnostic dataset an evaluation toolkit that measures visual reasoning skills ([paper](https://arxiv.org/abs/2202.04053)).
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_reasoning_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: winoground
    display_name: Winoground
    description: Winoground is a novel task and dataset for evaluating the ability of vision and language models to conduct visio-linguistic compositional reasoning ([paper](https://arxiv.org/abs/2204.03162)).
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_quality_automated_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Reasoning
  - name: parti_prompts_knowledge
    display_name: PartiPrompts (knowledge categories)
    description: PartiPrompts (P2) is a set of 1600 diverse English prompts that allow us to more comprehensively evaluate and test the limits of text-to-image synthesis models.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Knowledge
  - name: draw_bench_knowledge
    display_name: DrawBench (knowledge categories)
    description: A comprehensive and challenging set of prompts that support the evaluation and comparison of text-to-image models.
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Knowledge
  - name: time_most_significant_historical_figures
    display_name: TIME's most significant historical figures
    description: People from TIME's "The 100 Most Significant Figures in History" list
    metric_groups:
      - heim_alignment_human_metrics
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Knowledge
  - name: demographic_stereotypes
    display_name: Demographic Stereotypes
    description: Simple user prompts ("A photo of the face of...") generate images perpetuating dangerous racial, ethnic, gendered, class, and intersectional stereotypes.
    metric_groups:
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_bias_metrics
      - heim_gender_metrics
      - heim_skin_tone_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Unbiasedness
  - name: mental_disorders
    display_name: Mental Disorders
    description: Prompt text-to-image models with mental disorders listed by the World Health Organization
    metric_groups:
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_bias_metrics
      - heim_gender_metrics
      - heim_skin_tone_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Unbiasedness
  - name: i2p
    display_name: Inappropriate Image Prompts (I2P)
    description: Contains real user prompts for generative text-to-image prompts that are likely to produce inappropriate images ([paper](https://arxiv.org/abs/2211.05105)).
    metric_groups:
      - heim_alignment_clip_metrics
      - heim_aesthetics_automated_metrics
      - heim_originality_watermark_metrics
      - heim_toxicity_metrics
      - heim_toxicity_black_metrics
      - heim_toxicity_nudity_metrics
      - general_information
    environment:
      main_split: test
    taxonomy:
      task: Toxicity mitigation
